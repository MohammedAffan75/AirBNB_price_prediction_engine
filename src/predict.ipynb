{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56d287d3",
   "metadata": {},
   "source": [
    "# Airbnb Price Prediction\n",
    "This notebook loads the trained model and generates predictions for the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c447b337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (20000, 32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the cleaned test dataset\n",
    "%store -r test_df_cleaned\n",
    "print(\"Test data shape:\", test_df_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06e5e886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "pipe = joblib.load('../models/airbnb_price_model.joblib')\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b83d739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test features shape: (20000, 15)\n"
     ]
    }
   ],
   "source": [
    "# Define feature columns (same as in training)\n",
    "numeric_features = [\n",
    "    'accommodates', 'bathrooms', 'bedrooms', 'beds',\n",
    "    'review_scores_rating', 'number_of_reviews', 'month'\n",
    "]\n",
    "\n",
    "binary_features = [\n",
    "    'has_wifi', 'host_verified', 'host_has_pic', 'instant_bookable'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'room_type', 'property_type', 'cancellation_policy', 'city'\n",
    "]\n",
    "\n",
    "# Combine all features\n",
    "feature_cols = numeric_features + binary_features + categorical_features\n",
    "\n",
    "# Prepare test features\n",
    "X_test = test_df_cleaned[feature_cols]\n",
    "print(\"Test features shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9f2c8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "\n",
      "Predictions saved to 'c:\\Users\\MOHAMMED AFFAN\\OneDrive\\Desktop\\AIRBNB\\output\\predictions.csv'\n",
      "Preview of predictions:\n",
      "   id       price\n",
      "0   0   61.403321\n",
      "1   1  128.005335\n",
      "2   2  164.199786\n",
      "3   3  168.448307\n",
      "4   4  144.088999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MOHAMMED AFFAN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:228: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "print(\"Generating predictions...\")\n",
    "y_pred_test = pipe.predict(X_test)\n",
    "\n",
    "# Convert log predictions back to original scale\n",
    "y_pred_test_original = np.exp(y_pred_test) - 1\n",
    "\n",
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df_cleaned.index,\n",
    "    'price': y_pred_test_original\n",
    "})\n",
    "\n",
    "# Ensure output directory exists and save predictions\n",
    "import os\n",
    "output_dir = os.path.abspath(os.path.join('..', 'output'))\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'predictions.csv')\n",
    "submission.to_csv(output_path, index=False)\n",
    "print(f\"\\nPredictions saved to '{output_path}'\")\n",
    "print(\"Preview of predictions:\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5faa2d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from '../models/airbnb_price_model.joblib'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MOHAMMED AFFAN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:228: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearExplainer failed (falling back to KernelExplainer): The option feature_dependence has been renamed to feature_perturbation!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 75.13it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP summary saved to c:\\Users\\MOHAMMED AFFAN\\OneDrive\\Desktop\\AIRBNB\\output\\shap_summary.png\n"
     ]
    }
   ],
   "source": [
    "# SHAP explanations (robust: loads model/data if missing)\n",
    "import os\n",
    "import numpy as np\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# Ensure model is loaded\n",
    "if 'pipe' not in globals():\n",
    "    try:\n",
    "        pipe = joblib.load('../models/airbnb_price_model.joblib')\n",
    "        print(\"Model loaded from '../models/airbnb_price_model.joblib'\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\"Trained model not found. Run training notebook first or ensure model file exists.\") from e\n",
    "\n",
    "# Ensure train/test cleaned data and feature_cols are available\n",
    "if 'train_df_cleaned' not in globals():\n",
    "    get_ipython().run_line_magic('store', '-r train_df_cleaned')\n",
    "if 'test_df_cleaned' not in globals():\n",
    "    get_ipython().run_line_magic('store', '-r test_df_cleaned')\n",
    "\n",
    "if 'feature_cols' not in globals():\n",
    "    # Define fallback feature lists (must match training)\n",
    "    numeric_features = [\n",
    "        'accommodates', 'bathrooms', 'bedrooms', 'beds',\n",
    "        'review_scores_rating', 'number_of_reviews', 'month'\n",
    "    ]\n",
    "    binary_features = [\n",
    "        'has_wifi', 'host_verified', 'host_has_pic', 'instant_bookable'\n",
    "    ]\n",
    "    categorical_features = [\n",
    "        'room_type', 'property_type', 'cancellation_policy', 'city'\n",
    "    ]\n",
    "    feature_cols = numeric_features + binary_features + categorical_features\n",
    "\n",
    "# Use the pipeline's preprocessor to transform features\n",
    "pre = pipe.named_steps.get('preprocessor') or pipe.named_steps.get('pre')\n",
    "reg = pipe.named_steps.get('regressor') or pipe.named_steps.get('model')\n",
    "if pre is None or reg is None:\n",
    "    raise RuntimeError('Expected pipeline to contain \"preprocessor\" and \"regressor\" steps')\n",
    "\n",
    "X_train_pre = pre.transform(train_df_cleaned[feature_cols])\n",
    "X_test_pre = pre.transform(test_df_cleaned[feature_cols])\n",
    "\n",
    "# Prepare background sample\n",
    "rng = np.random.default_rng(42)\n",
    "bg_size = min(100, X_train_pre.shape[0])\n",
    "bg_idx = rng.choice(X_train_pre.shape[0], size=bg_size, replace=False)\n",
    "background = X_train_pre[bg_idx]\n",
    "\n",
    "# Try LinearExplainer first (fast for linear models), else fall back\n",
    "try:\n",
    "    explainer = shap.LinearExplainer(reg, background, feature_dependence='independent')\n",
    "    shap_values = explainer.shap_values(X_test_pre[:200])\n",
    "except Exception as e:\n",
    "    print('LinearExplainer failed (falling back to KernelExplainer):', e)\n",
    "    explainer = shap.KernelExplainer(reg.predict, background)\n",
    "    shap_values = explainer.shap_values(X_test_pre[:200], nsamples=100)\n",
    "\n",
    "# Build feature names after preprocessing (numeric + binary + one-hoted categorical)\n",
    "feature_names = []\n",
    "try:\n",
    "    # numeric and binary keep their names\n",
    "    feature_names.extend(numeric_features)\n",
    "    feature_names.extend(binary_features)\n",
    "    # categorical one-hot names\n",
    "    cat_tm = pre.named_transformers_.get('cat')\n",
    "    if cat_tm is not None:\n",
    "        # cat_tm is a Pipeline with a OneHotEncoder named 'onehot'\n",
    "        if hasattr(cat_tm, 'named_steps') and 'onehot' in cat_tm.named_steps:\n",
    "            onehot = cat_tm.named_steps['onehot']\n",
    "        else:\n",
    "            onehot = cat_tm\n",
    "        try:\n",
    "            cat_names = onehot.get_feature_names_out(categorical_features).tolist()\n",
    "        except AttributeError:\n",
    "            cat_names = onehot.get_feature_names(categorical_features).tolist()\n",
    "        feature_names.extend(cat_names)\n",
    "except Exception:\n",
    "    # fallback to generic names\n",
    "    feature_names = [f'f{i}' for i in range(X_test_pre.shape[1])]\n",
    "\n",
    "# Plot and save\n",
    "plt.figure(figsize=(10,6))\n",
    "shap.summary_plot(shap_values, features=X_test_pre[:200], feature_names=feature_names, show=False)\n",
    "output_dir = os.path.abspath(os.path.join('..', 'output'))\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "shap_output = os.path.join(output_dir, 'shap_summary.png')\n",
    "plt.savefig(shap_output, bbox_inches='tight')\n",
    "print(f\"SHAP summary saved to {shap_output}\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45ac1773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved listings for dashboard to c:\\Users\\MOHAMMED AFFAN\\OneDrive\\Desktop\\AIRBNB\\output\\listings_for_dashboard.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%store -r train_df_cleaned\n",
    "# Save listings for dashboard (robust)\n",
    "import os\n",
    "\n",
    "# Restore train dataframe if needed\n",
    "if 'train_df_cleaned' not in globals():\n",
    "    get_ipython().run_line_magic('store', '-r', 'train_df_cleaned')\n",
    "\n",
    "# Prepare output directory at project root\n",
    "output_dir = os.path.abspath(os.path.join('..', 'output'))\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "train_df_export = train_df_cleaned.copy()\n",
    "if 'id' not in train_df_export.columns:\n",
    "    train_df_export = train_df_export.reset_index().rename(columns={'index': 'id'})\n",
    "\n",
    "cols_list = ['id', 'neighbourhood', 'room_type', 'property_type', 'accommodates',\n",
    "             'latitude', 'longitude', 'review_scores_rating', 'price']\n",
    "cols_list_existing = [c for c in cols_list if c in train_df_export.columns]\n",
    "\n",
    "if not cols_list_existing:\n",
    "    print('No expected columns found in train_df_cleaned; skipping CSV save.')\n",
    "else:\n",
    "    listings_path = os.path.join(output_dir, 'listings_for_dashboard.csv')\n",
    "    train_df_export[cols_list_existing].to_csv(listings_path, index=False)\n",
    "    print(f\"Saved listings for dashboard to {listings_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
